services:
  backend:
    build: ./backend
    container_name: marketing-brain-backend
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      # CORS para frontend dentro de Docker
      - BACKEND_CORS_ORIGINS=http://localhost:3000,http://frontend:3000
      # TAREA 6.4: Procesamiento paralelo de chunks de libros
      - BOOK_PARALLEL_CHUNKS=10
    volumes:
      # ✅ GOTCHA Windows/WSL: named volume para almacenamiento interno
      - backend_storage:/app/storage
      # Bind mount solo de código fuente para desarrollo (opcional)
      - ./backend/src:/app/src:ro
    depends_on:
      - redis
    # TAREA 6.4: Límites de recursos para estabilidad
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G

  frontend:
    build: ./frontend
    container_name: marketing-brain-frontend
    ports:
      - "3000:3000"
    environment:
      # El frontend habla con el backend por nombre de servicio dentro de la red de Docker
      - NEXT_PUBLIC_API_URL=http://localhost:8000
    volumes:
      # Bind mounts de código para DX en desarrollo
      - ./frontend/app:/app/app:ro
      - ./frontend/lib:/app/lib:ro
    depends_on:
      - backend
    # TAREA 6.4: Límites de recursos (frontend es ligero)
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  redis:
    image: redis:7-alpine
    container_name: marketing-brain-redis
    ports:
      - "6379:6379"
    volumes:
      # ✅ GOTCHA 8: named volume en vez de bind mount
      - redis_data:/data
    # TAREA 6.4: Límites de recursos para Redis
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # MCP server como servicio HTTP (para integración con Cursor via HTTP)
  mcp-marketing-brain:
    build: ./mcp-marketing-brain
    container_name: marketing-brain-mcp
    ports:
      - "8080:8080"
    environment:
      - BACKEND_API_URL=http://backend:8000
      - MCP_TRANSPORT=http
      - MCP_HOST=0.0.0.0
      - MCP_PORT=8080
      # Si usas JWT o API key para llamadas internas, configúralo aquí:
      # - BACKEND_API_TOKEN=...
    depends_on:
      - backend

volumes:
  backend_storage:
  redis_data:

