# ğŸ§  Marketing Second Brain System

> Sistema web full-stack de segundo cerebro para estrategia de marketing digital con agente IA, memoria persistente y generaciÃ³n de contenido personalizado

---

## ğŸ“Œ Â¿QuÃ© es esto?

Un sistema inteligente que:

1. **Analiza tu negocio** â†’ Creas tu buyer persona automÃ¡ticamente
2. **Simula comportamiento** â†’ El agente actÃºa como tu cliente ideal
3. **Mapea el customer journey** â†’ 3 fases con 20+ preguntas por fase
4. **Genera contenido on-demand** â†’ Ideas de videos, posts, artÃ­culos personalizados
5. **Aprende de expertos** â†’ Entrenado con transcripciones de YouTubers + libros de marketing

---

## ğŸ¯ Diferenciadores Clave

| CaracterÃ­stica | DescripciÃ³n |
|----------------|-------------|
| ğŸ¤– **Agente IA Multi-Especializado** | 7 agentes (Router, Buyer Persona, Forum Simulator, Pain Points, Customer Journey, Content Generator, Document Processor) |
| ğŸ§  **Memoria Triple** | Short-term (10 Ãºltimos mensajes), Long-term (DB completa), Semantic (bÃºsqueda vectorial) |
| ğŸ“š **RAG con Conocimiento Experto** | Transcripciones de YouTubers + RAG tradicional |
| ğŸ“– **Aprendizaje Progresivo de Libros** | **ğŸ†•** Extrae conceptos estructurados (no solo chunks) de libros de marketing |
| ğŸ“„ **Upload de Documentos** | Sube archivos `.txt`, `.pdf`, `.docx` con info de tu negocio |
| â¸ï¸ **No Genera AutomÃ¡ticamente** | Usuario controla cuÃ¡ndo generar contenido (no spam) |
| ğŸ”’ **Multi-Tenancy Estricto** | Aislamiento total por `project_id` |
| ğŸš€ **Streaming de Respuestas** | SSE (Server-Sent Events) para respuestas en tiempo real |

---

## ğŸ› ï¸ Stack TecnolÃ³gico

### Frontend
- **Next.js 14** (App Router)
- **TypeScript** + **React 18**
- **TailwindCSS** + **shadcn/ui**
- **Zustand** (estado global)
- **Server-Sent Events** (streaming)

### Backend
- **FastAPI** (Python 3.11+)
- **Pydantic v2** (validaciÃ³n)
- **SQLAlchemy 2.0** + **Alembic** (ORM + migraciones)
- **LangChain** + **LangGraph** (agentes)
- **Anthropic Claude 3.5 Sonnet** (LLM)
- **OpenAI** (embeddings)

### Database
- **Supabase** (PostgreSQL + pgvector)
- **pgvector** (bÃºsqueda vectorial)

### Infrastructure
- **Docker** + **Docker Compose**
- **Redis** (opcional, cachÃ©)

---

## ğŸ“ Estructura del Proyecto

```bash
/home/david/brain-mkt/
â”œâ”€â”€ README.md                           # â† Este archivo
â”œâ”€â”€ .env.example                        # Plantilla de variables de entorno
â”œâ”€â”€ docker-compose.yml                  # OrquestaciÃ³n de 4 servicios
â”‚
â”œâ”€â”€ frontend/                           # Next.js 14 App
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ components/                 # ChatInterface, Sidebar, TracePanel
â”‚   â”‚   â”œâ”€â”€ page.tsx                    # PÃ¡gina principal
â”‚   â”‚   â””â”€â”€ layout.tsx
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â””â”€â”€ api-chat.ts                 # Utilidades API (CRUD chats)
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ backend/                            # FastAPI App
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/                        # Endpoints (auth, chat, documents)
â”‚   â”‚   â”œâ”€â”€ agents/                     # 7 agentes IA
â”‚   â”‚   â”‚   â”œâ”€â”€ router_agent.py         # Orquestador principal
â”‚   â”‚   â”‚   â”œâ”€â”€ content_generator_agent.py  # Generador de ideas
â”‚   â”‚   â”‚   â”œâ”€â”€ buyer_persona_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ forum_simulator_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ pain_points_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ customer_journey_agent.py
â”‚   â”‚   â”‚   â””â”€â”€ document_processor_agent.py
â”‚   â”‚   â”œâ”€â”€ services/                   # LLM, embeddings, memory
â”‚   â”‚   â”œâ”€â”€ db/                         # Models SQLAlchemy
â”‚   â”‚   â””â”€â”€ schemas/                    # Pydantic schemas
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ ingest_training_data.py
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ mcp-marketing-brain/                # ğŸ†• MCP Server
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ server.py                   # FastMCP con 3 tools
â”‚   â”œâ”€â”€ pyproject.toml                  # Dependencias: mcp, httpx, uvicorn
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ contenido/                          # Material de entrenamiento
â”‚   â”œâ”€â”€ buyer-plantilla.md
â”‚   â”œâ”€â”€ prompts-mejorados-v2.md
â”‚   â””â”€â”€ Transcriptions Andrea Estratega/
â”‚
â”œâ”€â”€ docs/                               # DocumentaciÃ³n tÃ©cnica
â”‚   â”œâ”€â”€ gotchas-detallados-y-soluciones.md
â”‚   â”œâ”€â”€ supabase-self-hosted-setup.md
â”‚   â””â”€â”€ qa-plan3-tecnicas-aplicadas.md  # ğŸ†• QA manual
â”‚
â”œâ”€â”€ PRPs/                               # Product Requirement Prompts
â”‚   â””â”€â”€ marketing-brain-system-v3.md
â”‚
â””â”€â”€ Context-Engineering-Intro/         # Ejemplos y templates de referencia
```

---

## ğŸš€ Quick Start

### 1. Clonar Repositorio

```bash
git clone <repo-url>
cd brain-mkt
```

### 2. Configurar Variables de Entorno

```bash
# Copiar plantilla
cp .env.example .env

# Editar con tus credenciales
nano .env

# Variables REQUERIDAS:
# - SUPABASE_URL              # URL de tu instancia Supabase
# - SUPABASE_SERVICE_ROLE_KEY # Service role key (Admin)
# - ANTHROPIC_API_KEY         # API key de Anthropic
# - OPENAI_API_KEY            # API key de OpenAI (embeddings)
# - JWT_SECRET_KEY            # Secret para tokens JWT
```

**ğŸ“š GuÃ­a**: Ver `docs/supabase-self-hosted-setup.md` si usas Supabase en VPS

### 3. Configurar Base de Datos

```bash
# Conectar a PostgreSQL (Supabase)
psql $SUPABASE_DB_URL

# Ejecutar SQL del PRP (TAREA 1)
# Ver: PRPs/marketing-brain-system-v3.md
# SecciÃ³n: "TAREA 1: Configurar Base de Datos en Supabase"
```

### 4. Iniciar Servicios con Docker

```bash
# Construir y levantar todos los servicios
docker compose up --build -d

# Verificar que todo estÃ¡ corriendo
docker compose ps

# Esperado: 4 contenedores "Up"
# - marketing-brain-frontend (3000)
# - marketing-brain-backend  (8000)
# - marketing-brain-mcp      (8080)
# - marketing-brain-redis    (6379)
```

### 5. Ingestar Material de Entrenamiento

```bash
# Procesar transcripciones de Andrea Estratega
docker compose exec backend python scripts/ingest_training_data.py \
  --source "contenido/Transcriptions Andrea Estratega/" \
  --content-type video_transcript

# Esperado: ~200-500 chunks procesados
```

### 6. Acceder a la AplicaciÃ³n

| Servicio | URL | DescripciÃ³n |
|----------|-----|-------------|
| **Frontend** | http://localhost:3000 | Interfaz de usuario |
| **Backend API** | http://localhost:8000 | API REST |
| **API Docs** | http://localhost:8000/docs | Swagger/OpenAPI |
| **MCP Server** | http://localhost:8080/mcp | MCP para Cursor |

---

## ğŸ³ Docker Architecture

El sistema usa Docker Compose para orquestar 4 servicios:

```yaml
services:
  frontend:        # Next.js 14 (puerto 3000)
  backend:         # FastAPI (puerto 8000)
  mcp-marketing-brain:  # MCP Server (puerto 8080)
  redis:           # Cache (puerto 6379)
```

### Comandos Docker Ãštiles

```bash
# Iniciar todos los servicios
docker compose up -d

# Ver logs de un servicio especÃ­fico
docker compose logs -f backend

# Reconstruir un servicio
docker compose up --build -d backend

# Detener todos los servicios
docker compose down

# Limpiar volÃºmenes (CUIDADO: borra datos)
docker compose down -v
```

### Variables de Entorno Docker

El archivo `docker-compose.yml` configura:

- `NEXT_PUBLIC_API_URL=http://localhost:8000` - URL del backend para el frontend
- `BACKEND_CORS_ORIGINS` - OrÃ­genes permitidos para CORS
- `MCP_TRANSPORT=http` - Transporte HTTP para el MCP server

---

## ğŸ”Œ MCP Server (Model Context Protocol)

El proyecto incluye un servidor MCP para integraciÃ³n con Cursor/Claude Desktop.

### Tools Disponibles

| Tool | DescripciÃ³n |
|------|-------------|
| `mb_list_chats` | Lista todos los chats del proyecto |
| `mb_get_chat_analysis` | Obtiene anÃ¡lisis completo (buyer persona, foro, journey) |
| `mb_generate_content_ideas_stub` | Placeholder para generaciÃ³n de contenido |

### ConfiguraciÃ³n en Cursor

Para usar el MCP con Cursor, agrega a tu configuraciÃ³n MCP:

```json
{
  "mcpServers": {
    "marketing-brain": {
      "command": "npx",
      "args": ["mcp-remote", "http://localhost:8080/mcp"],
      "env": {}
    }
  }
}
```

### Variables de Entorno MCP

```bash
# En docker-compose.yml o .env
MCP_TRANSPORT=http          # Transporte: stdio | http
MCP_HOST=0.0.0.0           # Host (0.0.0.0 para Docker)
MCP_PORT=8080              # Puerto
BACKEND_API_URL=http://backend:8000  # URL del backend (interno Docker)
```

---

## ğŸ“– DocumentaciÃ³n Clave

| Documento | PropÃ³sito |
|-----------|-----------|
| **PRPs/marketing-brain-system-v3.md** | PRP completo con 11 tareas detalladas |
| **docs/gotchas-detallados-y-soluciones.md** | 10 problemas tÃ©cnicos crÃ­ticos con soluciones validadas |
| **docs/supabase-self-hosted-setup.md** | GuÃ­a de instalaciÃ³n de Supabase en VPS |
| **contenido/buyer-plantilla.md** | Plantilla base para buyer persona (11 categorÃ­as) |
| **contenido/prompts-mejorados-v2.md** | Prompts con tÃ©cnicas avanzadas (Chain-of-Thought, Few-Shot) |

---

## ğŸ” Componentes Principales

### ğŸ¤– Agentes IA

1. **RouterAgent**: Orquestador principal, detecta intenciÃ³n del usuario
2. **DocumentProcessorAgent**: Procesa archivos subidos (.txt, .pdf, .docx)
3. **BuyerPersonaAgent**: Genera buyer persona completo (11 categorÃ­as, 40+ preguntas)
4. **ForumSimulatorAgent**: Simula persona en foro (quejas + soluciones)
5. **PainPointsAgent**: Extrae 10 puntos de dolor
6. **CustomerJourneyAgent**: Crea customer journey (3 fases Ã— 20 preguntas)
7. **ContentGeneratorAgent**: Genera ideas de contenido on-demand

### ğŸ§  Sistema de Memoria

```python
class MemoryManager:
    """
    GestiÃ³n de memoria triple:
    
    1. SHORT-TERM: ConversationBufferWindowMemory (k=10)
       - Ãšltimos 10 mensajes de conversaciÃ³n
       - Para contexto inmediato
    
    2. LONG-TERM: PostgreSQL (marketing_messages, marketing_buyer_personas)
       - Historial completo de chats
       - Buyer personas generados
       - Customer journeys
    
    3. SEMANTIC: pgvector (marketing_knowledge_base)
       - Transcripciones de YouTubers (project_id=NULL)
       - Documentos subidos por usuario (project_id=especÃ­fico)
       - BÃºsqueda vectorial con embeddings OpenAI
    """
```

### ğŸ“š Sistema de Aprendizaje Progresivo de Libros

El sistema incluye un pipeline avanzado para aprender de libros y documentos largos. A diferencia de un RAG tradicional que solo guarda chunks de texto, este sistema **extrae conocimiento estructurado**.

#### Â¿Por quÃ© tarda en procesar un libro?

| Sistema | Pipeline | Velocidad |
|---------|----------|-----------|
| **RAG tradicional** | Chunk â†’ Embed â†’ Guardar | âš¡ Segundos |
| **Nuestro sistema** | Chunk â†’ **LLM extrae conceptos** â†’ Embed â†’ Guardar | ğŸ¢ Minutos |

Cada chunk del libro pasa por un LLM que extrae:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    POR CADA CHUNK SE EXTRAE:                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ main_concepts     â”‚ Conceptos principales (mÃ¡x 5)               â”‚
â”‚                   â”‚ Ej: ["Hook", "Dream 100", "Traffic Funnel"] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ relationships     â”‚ Relaciones entre conceptos                  â”‚
â”‚                   â”‚ Ej: ["Hook captura atenciÃ³n â†’ Funnel        â”‚
â”‚                   â”‚      convierte", "Dream 100 genera Warm     â”‚
â”‚                   â”‚      Traffic"]                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ key_examples      â”‚ Ejemplos concretos del libro                â”‚
â”‚                   â”‚ Ej: ["Russell contactÃ³ 100 influencers      â”‚
â”‚                   â”‚      para su primer lanzamiento"]           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ technical_terms   â”‚ TÃ©rminos tÃ©cnicos con definiciones          â”‚
â”‚                   â”‚ Ej: {"Dream 100": "Lista de 100 personas    â”‚
â”‚                   â”‚      que ya tienen tu audiencia ideal"}     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ condensed_text    â”‚ Resumen condensado del chunk (mÃ¡x 2000      â”‚
â”‚                   â”‚ chars) optimizado para embedding            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Â¿Por quÃ© es mejor que RAG tradicional?

| RAG Tradicional | Nuestro Sistema |
|-----------------|-----------------|
| Guarda texto crudo | Guarda **conocimiento estructurado** |
| LLM debe "entender" el chunk | LLM recibe conceptos **pre-digeridos** |
| Busca por similitud de texto | Busca por similitud de **conceptos** |
| Puede ignorar info importante | Conceptos clave ya estÃ¡n extraÃ­dos |

#### Flujo de procesamiento de un libro:

```
1. UPLOAD
   Usuario sube PDF/TXT/DOCX en "Libros Aprendidos"
   
2. CHUNKING  
   RecursiveCharacterTextSplitter (1500 chars, 200 overlap)
   
3. EXTRACCIÃ“N DE CONCEPTOS (por cada chunk)
   LLM extrae: main_concepts, relationships, key_examples, 
              technical_terms, condensed_text
   
4. EMBEDDINGS
   OpenAI text-embedding-3-small genera vector de condensed_text
   
5. ALMACENAMIENTO
   - marketing_learned_books: Metadatos + global_summary
   - marketing_book_concepts: Conceptos por chunk con embeddings
   
6. GLOBAL SUMMARY
   LLM genera resumen ejecutivo del libro completo
```

#### CÃ³mo se aplica en las conversaciones:

```
Usuario pregunta: "Dame ideas de hooks para TikTok"
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BÃºsqueda semÃ¡ntica en marketing_book_concepts                â”‚
â”‚ â†’ Encuentra conceptos relevantes por embedding               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Se inyecta en el System Prompt:                              â”‚
â”‚                                                              â”‚
â”‚ ## CONOCIMIENTO APRENDIDO DE LIBROS:                         â”‚
â”‚                                                              â”‚
â”‚ ğŸ“š DE 'Traffic Secrets - Russell Brunson':                   â”‚
â”‚   Conceptos: Hook, Pattern Interrupt, Dream 100              â”‚
â”‚   Resumen: El hook debe capturar atenciÃ³n en 3 segundos...   â”‚
â”‚   TÃ©rminos: Hook: Primera frase que detiene el scroll        â”‚
â”‚                                                              â”‚
â”‚ ğŸ“š DE 'Expert Secrets':                                      â”‚
â”‚   Conceptos: Story Selling, Origin Story, Epiphany Bridge    â”‚
â”‚   Resumen: Las historias venden mejor que los argumentos...  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
              LLM genera respuesta usando ese conocimiento
```

#### Tablas de la base de datos:

```sql
-- Metadatos de libros procesados
CREATE TABLE marketing_learned_books (
    id UUID PRIMARY KEY,
    project_id UUID NOT NULL,
    title VARCHAR(500) NOT NULL,
    author VARCHAR(255),
    processing_status VARCHAR(50),  -- pending/processing/completed/failed
    total_chunks INTEGER,
    processed_chunks INTEGER,
    global_summary JSONB,           -- Resumen ejecutivo del libro
    created_at TIMESTAMP,
    completed_at TIMESTAMP
);

-- Conceptos extraÃ­dos por chunk
CREATE TABLE marketing_book_concepts (
    id UUID PRIMARY KEY,
    learned_book_id UUID REFERENCES marketing_learned_books(id),
    chunk_index INTEGER NOT NULL,
    main_concepts TEXT[],           -- Array de conceptos
    relationships TEXT[],           -- Array de relaciones
    key_examples TEXT[],            -- Array de ejemplos
    technical_terms JSONB,          -- {tÃ©rmino: definiciÃ³n}
    condensed_text TEXT,            -- Resumen para embedding
    embedding VECTOR(1536),         -- Vector OpenAI
    created_at TIMESTAMP
);
```

#### Tiempo estimado de procesamiento:

| TamaÃ±o del libro | Chunks aprox. | Tiempo estimado |
|------------------|---------------|-----------------|
| 50 pÃ¡ginas | ~50 chunks | 3-5 minutos |
| 200 pÃ¡ginas | ~200 chunks | 10-15 minutos |
| 400+ pÃ¡ginas | ~400+ chunks | 20-30 minutos |

> **Nota**: Cada chunk requiere una llamada al LLM para extraer conceptos. El procesamiento es en batches de 10 chunks para evitar rate limits.

#### Verificar progreso de un libro:

```bash
# Ver estado en la base de datos
docker run --rm postgres:15-alpine psql "$SUPABASE_DB_URL" -c "
SELECT title, processing_status, processed_chunks, total_chunks 
FROM marketing_learned_books 
ORDER BY created_at DESC;
"

# Ver logs de procesamiento
docker logs marketing-brain-backend 2>&1 | grep "\[BOOK\]"
# Output: [BOOK] batch book_id=xxx processed=50/200
```

---

### ğŸ“Š Base de Datos

**Tablas principales:**
- `marketing_projects`: Proyectos (multi-tenancy)
- `marketing_users`: Usuarios con autenticaciÃ³n manual (JWT)
- `marketing_chats`: Conversaciones
- `marketing_messages`: Mensajes individuales
- `marketing_buyer_personas`: Buyer personas generados
- `marketing_knowledge_base`: Base de conocimiento vectorial (RAG tradicional)
- `marketing_user_documents`: Documentos subidos
- `marketing_learned_books`: **ğŸ†•** Libros procesados (metadatos + resumen global)
- `marketing_book_concepts`: **ğŸ†•** Conceptos estructurados extraÃ­dos de libros

**Ãndices crÃ­ticos:**
- HNSW en `embedding` columns (NO ivfflat con <1000 docs)
- Ãndices compuestos en `(user_id, project_id)`

---

## ğŸ” Seguridad

### AutenticaciÃ³n
- **Manual JWT** (NO Supabase Auth debido a limitaciones de correo)
- Tokens con 7 dÃ­as de expiraciÃ³n
- Cookies `httpOnly` + `secure` en producciÃ³n

### Aislamiento Multi-Tenant
```python
# âœ… TODAS las queries incluyen project_id
chats = db.chats.find({
    'user_id': user_id,
    'project_id': project_id  # â† OBLIGATORIO
})

# âŒ NUNCA queries sin project_id
chats = db.chats.find({'user_id': user_id})  # â† PELIGRO
```

### Gotchas de Seguridad

âš ï¸ **GOTCHA 6**: Service Role Key bypasea RLS

```python
# Supabase Service Role Key NO respeta Row Level Security
# SoluciÃ³n: ValidaciÃ³n manual de project_id en backend
```

Ver: `docs/gotchas-detallados-y-soluciones.md` para los 10 gotchas crÃ­ticos

---

## ğŸ§ª Testing

```bash
# Tests unitarios
docker compose exec backend pytest tests/

# Tests de integraciÃ³n
docker compose exec backend pytest tests/integration/

# Coverage
docker compose exec backend pytest --cov=src tests/
```

---

## ğŸš¨ Troubleshooting

### Docker: "Cannot connect to database"
```bash
# Verificar variables de entorno
docker compose exec backend env | grep SUPABASE

# Ver logs del backend
docker compose logs backend | tail -50
```

### Docker: "Frontend cannot reach backend"
```bash
# Verificar que NEXT_PUBLIC_API_URL apunta a localhost, NO a 'backend'
# El navegador no puede resolver nombres de Docker network

# âœ… Correcto (para el navegador)
NEXT_PUBLIC_API_URL=http://localhost:8000

# âŒ Incorrecto
NEXT_PUBLIC_API_URL=http://backend:8000
```

### Docker: "MCP server not responding"
```bash
# Verificar logs del MCP
docker logs marketing-brain-mcp

# Esperado:
# INFO: Uvicorn running on http://0.0.0.0:8080

# Test endpoint
curl http://localhost:8080/mcp
# Esperado: {"jsonrpc":"2.0","error":{"code":-32600,...}}
```

### "OpenAI rate limit error"
```bash
# Verificar que usas batching en embeddings
# Ver: backend/src/services/embedding_service.py
# Batch size: 50 (reduce a 20 si sigues teniendo problemas)
```

### "pgvector slow queries"
```bash
# Verificar Ã­ndice HNSW (NO ivfflat con <1000 docs)
psql $SUPABASE_DB_URL -c "\d+ marketing_knowledge_base"

# Esperado: "hnsw" en columna embedding
```

### Agent: "Respuestas truncadas o incompletas"
```bash
# Verificar variables de tracing en .env
AGENT_TRACE=1
AGENT_TRACE_SHOW_PROMPTS=1
SSE_DEBUG=1

# Revisar panel de Trace en el frontend
# (botÃ³n "Trace (SSE debug)" en la interfaz)
```

MÃ¡s soluciones: `docs/gotchas-detallados-y-soluciones.md`

---

## ğŸ“ˆ Roadmap

### âœ… Fase 1 - MVP (Completado)
- [x] Base de datos configurada (PostgreSQL + pgvector)
- [x] Backend con autenticaciÃ³n JWT
- [x] Agente IA con memoria triple
- [x] Frontend bÃ¡sico Next.js

### âœ… Fase 2 - Features Avanzadas (Completado)
- [x] Upload de documentos (.txt, .pdf, .docx)
- [x] Streaming de respuestas (SSE)
- [x] Mejora de prompts (v2.0 con tÃ©cnicas avanzadas)
- [x] Panel de trazabilidad (debug) en frontend
- [x] Modo consultivo + modo ideas JSON
- [x] EdiciÃ³n y eliminaciÃ³n de chats

### âœ… Fase 3 - Production Ready (Completado)
- [x] MCP custom del proyecto (3 tools read-only)
- [x] Docker + deployment (4 servicios)
- [x] DocumentaciÃ³n completa (README actualizado)
- [ ] Testing end-to-end (skeletons pendientes)

### âœ… Fase 4 - Aprendizaje Progresivo (Completado)
- [x] Sistema de procesamiento de libros (PDF, TXT, DOCX)
- [x] ExtracciÃ³n de conceptos estructurados con LLM
- [x] Almacenamiento de main_concepts, relationships, key_examples
- [x] IntegraciÃ³n de conocimiento de libros en respuestas del agente
- [x] UI para gestiÃ³n de libros aprendidos
- [x] Respuestas en Markdown (eliminado formato JSON forzado)

### ğŸ”® Fase 5 - Futuras Mejoras (Planeado)
- [ ] Cache Redis para training_summary
- [ ] Procesamiento paralelo de chunks (acelerar 4x)
- [ ] GeneraciÃ³n de contenido via MCP
- [ ] Dashboard de analytics
- [ ] ExportaciÃ³n de contenido

---

## ğŸ¤ Contribuir

Este es un proyecto personal. Si quieres contribuir:

1. Fork el repo
2. Crea branch (`git checkout -b feature/amazing-feature`)
3. Commit cambios (`git commit -m 'Add amazing feature'`)
4. Push branch (`git push origin feature/amazing-feature`)
5. Abre Pull Request

---

## ğŸ“ Licencia

MIT License - Ver `LICENSE` para detalles

---

## ğŸ™ Agradecimientos

- **Anthropic Claude** (LLM)
- **OpenAI** (Embeddings)
- **Supabase** (Database + pgvector)
- **LangChain** (Agents framework)
- **Andrea Estratega** (Transcripciones de YouTube)

---

## ğŸ“ Contacto

**Autor**: David  
**Email**: [tu-email]  
**LinkedIn**: [tu-linkedin]

---

**Ãšltima actualizaciÃ³n**: 2026-01-31  
**VersiÃ³n**: 3.0.0 (Progressive Learning System)
