# üì° API de Streaming - SSE (Server-Sent Events)

## Descripci√≥n

La API de streaming permite recibir respuestas del asistente de IA en tiempo real, mostrando progreso mientras los agentes procesan la informaci√≥n.

## Endpoints

### 1. Streaming Endpoint

**POST** `/api/chats/{chat_id}/stream`

Env√≠a mensaje y recibe respuesta por streaming usando SSE.

**Headers requeridos:**
```
Authorization: Bearer {token}
Content-Type: application/json
```

**Body:**
```json
{
  "content": "Tu mensaje aqu√≠"
}
```

**Response:**
```
Content-Type: text/event-stream
Cache-Control: no-cache
Connection: keep-alive
X-Accel-Buffering: no

data: {"type": "status", "content": "Routing message..."}

data: {"type": "chunk", "content": "üìä Analizando buyer persona..."}

data: {"type": "chunk", "content": "‚úÖ An√°lisis completado"}

data: {"type": "done", "content": ""}

data: [DONE]

```

### 2. Non-Streaming Endpoint

**POST** `/api/chats/{chat_id}/messages`

Env√≠a mensaje y espera respuesta completa (sin streaming).

## Formato de Eventos SSE

Cada evento tiene el formato:

```typescript
{
  "type": "status" | "chunk" | "done" | "error",
  "content": string
}
```

### Tipos de Eventos

| Tipo | Descripci√≥n | Ejemplo |
|------|-------------|---------|
| `status` | Estado inicial del router | `"No hay buyer persona. Creando..."` |
| `chunk` | Fragmento de respuesta | `"üìä Analizando perfil..."` |
| `done` | Fin del procesamiento | `""` (vac√≠o) |
| `error` | Error durante streaming | `"Error: connection timeout"` |

La se√±al `[DONE]` marca el cierre final del stream.

## Ejemplo con JavaScript (Frontend)

```javascript
const eventSource = new EventSource(
  `http://localhost:8000/api/chats/${chatId}/stream`,
  {
    headers: {
      'Authorization': `Bearer ${token}`
    }
  }
);

eventSource.onmessage = (event) => {
  if (event.data === '[DONE]') {
    eventSource.close();
    return;
  }

  try {
    const data = JSON.parse(event.data);
    
    switch (data.type) {
      case 'status':
        console.log('Status:', data.content);
        break;
      case 'chunk':
        appendToChat(data.content);
        break;
      case 'done':
        console.log('Stream completed');
        break;
      case 'error':
        console.error('Error:', data.content);
        eventSource.close();
        break;
    }
  } catch (e) {
    console.error('Parse error:', e);
  }
};

eventSource.onerror = (error) => {
  console.error('EventSource failed:', error);
  eventSource.close();
};
```

## Ejemplo con curl

```bash
# Test r√°pido con curl
curl -N -X POST "http://localhost:8000/api/chats/{chat_id}/stream" \
  -H "Authorization: Bearer {token}" \
  -H "Content-Type: application/json" \
  -d '{"content": "Analiza mi buyer persona"}'
```

**Nota**: La opci√≥n `-N` es crucial para deshabilitar buffering en curl.

## Testing Automatizado

Ejecutar script de prueba:

```bash
# Configurar variables (opcional)
export TEST_USER_EMAIL="test@example.com"
export TEST_USER_PASSWORD="testpass123"

# Ejecutar test
./backend/scripts/test_streaming_endpoint.sh
```

El script autom√°ticamente:
1. Verifica que el servidor est√© corriendo
2. Autentica al usuario
3. Crea un chat de prueba
4. Env√≠a mensaje con streaming
5. Muestra eventos SSE en tiempo real

## ‚ö° GOTCHA 3 - Middleware y Streaming

**Problema**: Middleware que lee `request.body()` consume el stream y rompe SSE.

**Soluci√≥n**: En `main.py`, excluir endpoints de streaming:

```python
@app.middleware("http")
async def logging_middleware(request: Request, call_next):
    streaming_paths = ["/stream", "/sse"]
    
    if any(path in request.url.path for path in streaming_paths):
        # ‚úÖ NO leer body, pasar directamente
        return await call_next(request)
    
    # Para endpoints normales, procesar con body logging
    # ...
```

## Flujo Interno

```
User Message
     ‚Üì
Save to DB (user message)
     ‚Üì
RouterAgent.process_stream()
     ‚îú‚îÄ> Route to agent
     ‚îú‚îÄ> Yield status
     ‚îú‚îÄ> Execute agent
     ‚îÇ   ‚îú‚îÄ> BUYER_PERSONA: Progress updates
     ‚îÇ   ‚îú‚îÄ> CONTENT_GENERATION: Stream chunks (future)
     ‚îÇ   ‚îî‚îÄ> WAITING: Acknowledge
     ‚îú‚îÄ> Yield chunks
     ‚îî‚îÄ> Yield done
          ‚Üì
Save to DB (assistant message)
     ‚Üì
Close stream
```

## Headers Importantes

```python
headers = {
    "Cache-Control": "no-cache",         # Prevent caching
    "Connection": "keep-alive",          # Keep connection open
    "X-Accel-Buffering": "no"           # Disable nginx buffering
}
```

## Pr√≥ximas Mejoras (TAREA 7+)

- [ ] Content Generator Agent con streaming real de chunks
- [ ] Progress tracking m√°s granular
- [ ] Cancelaci√≥n de streams (AbortController)
- [ ] Retry autom√°tico en caso de desconexi√≥n
