# Explicaci√≥n del Sistema de Conocimiento - Marketing Brain

> **Fecha:** 2026-01-30  
> **Contexto:** Aclaraci√≥n t√©cnica sobre RAG vs Fine-tuning y c√≥mo funciona el sistema

---

## üìö Tabla de Contenidos

1. [La Verdad T√©cnica: RAG vs Fine-tuning](#la-verdad-t√©cnica)
2. [Comparaci√≥n Honesta con n8n](#comparaci√≥n-con-n8n)
3. [Cu√°ndo Usar Qu√© Approach](#cu√°ndo-usar-qu√©)
4. [Tutorial: System Prompts del Sistema](#tutorial-system-prompts)
5. [Limitaciones Actuales](#limitaciones-actuales)
6. [Recomendaciones de Mejora](#recomendaciones)

---

## üéØ La Verdad T√©cnica

### Lo que implementamos (Context Engineering / RAG):

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CONTEXT ENGINEERING / RAG                     ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Libro ‚Üí Chunks ‚Üí [Procesamiento] ‚Üí Vectores ‚Üí B√∫squeda ‚Üí       ‚îÇ
‚îÇ  ‚Üí Inyectar en PROMPT ‚Üí LLM genera respuesta                    ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  El modelo NO aprende nada. Solo recibe contexto relevante.     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Fine-tuning Real (lo que NO tenemos):

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FINE-TUNING REAL                              ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Dataset de entrenamiento ‚Üí Ajustar pesos del modelo ‚Üí          ‚îÇ
‚îÇ  ‚Üí Modelo MODIFICADO que "sabe" el contenido                    ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  El modelo S√ç aprende. El conocimiento est√° EN el modelo.       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Conclusi√≥n:** Nuestro sistema es RAG avanzado con extracci√≥n de conceptos, NO es fine-tuning. El 95% de soluciones "empresariales de IA" funcionan as√≠.

---

## ‚öñÔ∏è Comparaci√≥n con n8n

### Lo que hace n8n (correctamente):

| Paso | n8n | Nuestro Sistema |
|------|-----|-----------------|
| 1. Chunking | ‚úÖ Divide documentos | ‚úÖ Divide documentos |
| 2. Vectorizaci√≥n | ‚úÖ Embeddings | ‚úÖ Embeddings |
| 3. B√∫squeda | ‚úÖ Sem√°ntica | ‚úÖ Sem√°ntica |
| 4. **Reranking** | ‚úÖ S√≠, selecciona m√°s relevantes | ‚úÖ S√≠, con threshold |
| 5. Inyecci√≥n en prompt | ‚úÖ Contexto al LLM | ‚úÖ Contexto al LLM |

### Diferencia REAL:

| Aspecto | n8n | Nuestro Sistema |
|---------|-----|-----------------|
| **Procesamiento de chunks** | Chunks crudos (texto tal cual) | Extracci√≥n de conceptos estructurados (LLM procesa cada chunk) |
| **Formato almacenado** | Texto plano | JSON estructurado: `{main_concepts, technical_terms, examples}` |
| **Flexibilidad de prompts** | F√°cil de modificar en UI | Requiere editar c√≥digo Python |
| **Orquestaci√≥n** | Nodos visuales | C√≥digo con agentes especializados |
| **Memoria** | Nodo de memoria | MemoryManager con m√∫ltiples fuentes |

### Ventajas de n8n:
- UI visual para modificar flujos
- F√°cil integraci√≥n con herramientas externas
- R√°pido de prototipar
- Menor curva de aprendizaje

### Ventajas de c√≥digo propio:
- Control total sobre la l√≥gica
- Procesamiento m√°s sofisticado posible
- No dependes de nodos pre-hechos
- Escalabilidad sin l√≠mites de plataforma
- Personalizaci√≥n profunda de agentes

---

## üìä Cu√°ndo Usar Qu√©

| Caso de uso | Mejor approach |
|-------------|----------------|
| "Quiero que sepa sobre MI producto/servicio" | RAG (lo que tenemos) |
| "Quiero que escriba en MI estilo espec√≠fico" | Fine-tuning |
| "Quiero que use terminolog√≠a de MI industria" | RAG con extracci√≥n de t√©rminos |
| "Quiero que siga MI formato exacto siempre" | Fine-tuning o Few-shot en prompt |
| "Quiero que consulte MIS documentos" | RAG |

### ¬øCu√°ndo vale la pena Fine-tuning?

1. **S√≠ vale:** Cuando necesitas que el modelo siga un ESTILO muy espec√≠fico consistentemente
2. **No vale:** Para inyectar conocimiento factual (RAG es mejor)
3. **Consideraci√≥n:** Fine-tuning cuesta dinero y requiere dataset bien preparado

---

## üîß Tutorial: System Prompts del Sistema

### ¬øD√≥nde est√°n los System Prompts?

```
backend/src/agents/
‚îú‚îÄ‚îÄ router_agent.py         ‚Üí Decide qu√© agente usar
‚îú‚îÄ‚îÄ buyer_persona_agent.py  ‚Üí Genera buyer personas
‚îî‚îÄ‚îÄ content_generator_agent.py ‚Üí Genera contenido (EL PRINCIPAL)
```

### 1. RouterAgent - Decide qu√© hacer

**Archivo:** `backend/src/agents/router_agent.py`

**Ubicaci√≥n del prompt:** M√©todo `_get_system_prompt()`

```python
# L√≠neas ~45-80 aproximadamente
def _get_system_prompt(self) -> str:
    return """Eres un agente router inteligente...
    
    RUTAS DISPONIBLES:
    - content_generator: Para crear contenido
    - buyer_persona: Para analizar audiencia
    - general: Para preguntas generales
    
    Responde SOLO con JSON: {"route": "nombre_ruta", "confidence": 0.0-1.0}
    """
```

**‚ö†Ô∏è Limitaci√≥n:** Este prompt EXIGE respuesta en JSON. Es parte del sistema de routing.

---

### 2. ContentGeneratorAgent - El Principal

**Archivo:** `backend/src/agents/content_generator_agent.py`

**Ubicaci√≥n del prompt:** M√©todo `_build_system_prompt()`

```python
# L√≠neas ~150-250 aproximadamente
def _build_system_prompt(self, context: dict) -> str:
    # Extrae informaci√≥n del contexto
    buyer_persona = context.get("buyer_persona", {})
    relevant_docs = context.get("relevant_docs", [])
    learned_concepts = context.get("learned_concepts", [])
    
    # Construye el prompt din√°micamente
    return f"""
    ## ROL
    Eres un experto en marketing digital...
    
    ## BUYER PERSONA
    {buyer_persona_text}
    
    ## DOCUMENTOS RELEVANTES
    {docs_text}
    
    ## CONOCIMIENTO DE LIBROS
    {learned_concepts_text}
    
    ## INSTRUCCIONES DE FORMATO
    Responde en el formato solicitado...
    """
```

**C√≥mo modificarlo:**
1. Abre `backend/src/agents/content_generator_agent.py`
2. Busca el m√©todo `_build_system_prompt`
3. Modifica el string del prompt
4. Reinicia el backend: `docker compose restart backend`

---

### 3. BuyerPersonaAgent

**Archivo:** `backend/src/agents/buyer_persona_agent.py`

**Ubicaci√≥n del prompt:** Similar estructura, m√©todo que construye el system prompt.

---

### C√≥mo Ver el Prompt Actual en Acci√≥n

```bash
# Ver logs del backend con prompts (si tienes logging habilitado)
docker logs marketing-brain-backend -f | grep -i "system\|prompt"
```

### C√≥mo Hacer Cambios Seguros

1. **Backup:** Copia el archivo antes de modificar
2. **Cambio peque√±o:** Modifica una cosa a la vez
3. **Test:** Prueba en el chat
4. **Rollback:** Si falla, restaura el backup

```bash
# Ejemplo de backup
cp backend/src/agents/content_generator_agent.py backend/src/agents/content_generator_agent.py.bak
```

---

## ‚ö†Ô∏è Limitaciones Actuales

### 1. Formato de Respuesta Forzado a JSON

**Problema:** Varios agentes exigen respuestas en JSON estructurado.

**Impacto:** 
- Menos flexibilidad en el output
- Dif√≠cil agregar ejemplos few-shot
- El frontend espera estructura espec√≠fica

**Archivos afectados:**
- `router_agent.py` - Respuesta JSON obligatoria
- `content_generator_agent.py` - Posiblemente estructura forzada
- `buyer_persona_agent.py` - Estructura forzada

### 2. Prompts en C√≥digo, No en Config

**Problema:** Los prompts est√°n hardcodeados en Python.

**Impacto:**
- Necesitas saber Python para modificar
- Requiere reiniciar backend
- No hay versionado separado de prompts

**Soluci√≥n futura:** Mover prompts a archivos `.txt` o `.yaml` separados.

### 3. No Hay UI para Editar Prompts

**Problema:** No puedes modificar prompts desde el dashboard.

**Impacto:**
- Dependencia del desarrollador para cambios
- Ciclo de iteraci√≥n lento

### 4. Chat Auto-crea Conversaciones

**Problema:** Cada vez que entras al chat se crea una conversaci√≥n vac√≠a.

**Impacto:**
- Base de datos llena de chats basura
- UX confusa

---

## üí° Recomendaciones

### Corto Plazo (TAREA 6.2 y 6.3):

1. **Cambiar output a Markdown** - M√°s flexibilidad, mejor UX
2. **Arreglar auto-creaci√≥n de chats** - Solo crear cuando hay mensaje

### Mediano Plazo:

1. **Externalizar prompts** - Mover a archivos YAML/TXT editables
2. **Agregar UI de configuraci√≥n** - Panel para editar prompts
3. **Mejorar logging** - Ver qu√© prompt se us√≥ en cada request

### Largo Plazo:

1. **Evaluar fine-tuning** - Para casos espec√≠ficos de estilo
2. **A/B testing de prompts** - Comparar diferentes versiones
3. **M√©tricas de calidad** - Evaluar respuestas autom√°ticamente

---

## üìÅ Archivos Clave para Referencia

| Archivo | Prop√≥sito |
|---------|-----------|
| `backend/src/agents/router_agent.py` | Decide qu√© agente usar |
| `backend/src/agents/content_generator_agent.py` | Genera contenido - PROMPT PRINCIPAL |
| `backend/src/agents/buyer_persona_agent.py` | Analiza audiencia |
| `backend/src/services/memory_manager.py` | Recopila contexto de todas las fuentes |
| `backend/src/services/rag_service.py` | B√∫squeda sem√°ntica |
| `backend/src/services/llm_service.py` | Comunicaci√≥n con OpenAI/OpenRouter |
| `frontend/app/components/ChatInterface.tsx` | UI del chat |
| `frontend/app/components/MessageBubble.tsx` | Renderiza mensajes |

---

## üîç DIAGN√ìSTICO T√âCNICO DEL SISTEMA

### Problema 1: Formato JSON Forzado (TAREA 6.2)

**Ubicaci√≥n del problema:**
- `backend/src/agents/content_generator_agent.py` l√≠neas 420-449

**C√≥digo problem√°tico:**
```python
format_section = (
    """CR√çTICO: Responde SOLO con JSON v√°lido. No incluyas texto antes o despu√©s del JSON.
No uses markdown.

Estructura requerida:
{
  "ideas": [
    {
      "titulo": "...",
      "plataforma": "...",
      ...
    }
  ]
}
"""
```

**Flujo actual:**
1. Usuario pide: "Dame 5 ideas de contenido"
2. Sistema detecta `mode = "ideas_json"` 
3. Prompt FUERZA respuesta en JSON
4. LLM responde con JSON estructurado
5. `router_agent.py` convierte JSON ‚Üí texto con formato (l√≠neas 262-313)
6. Frontend muestra texto plano (NO Markdown real)

**Problemas:**
- Limita creatividad del LLM (formato r√≠gido)
- Dif√≠cil agregar ejemplos few-shot
- El frontend NO renderiza Markdown real (solo `whitespace-pre-wrap`)

---

### Problema 2: Auto-creaci√≥n de Chats (TAREA 6.3)

**Ubicaci√≥n del problema:**
- `frontend/app/components/ChatPageContent.tsx` l√≠neas 27-38

**C√≥digo problem√°tico:**
```typescript
if (chatIdFromUrl) {
  setChatId(chatIdFromUrl)
} else {
  // ‚ö†Ô∏è PROBLEMA: Crea chat autom√°ticamente
  const newChat = await createChat({ title: 'Nueva Conversaci√≥n' })
  setChatId(newChat.id)
  router.replace(`/?chat=${newChat.id}`)
}
```

**Comportamiento actual:**
- Usuario entra a `/` ‚Üí Se crea chat vac√≠o
- Usuario refresca ‚Üí Se crea OTRO chat vac√≠o
- Resultado: Base de datos llena de chats basura

**Comportamiento deseado (como ChatGPT):**
- Usuario entra ‚Üí Ve lista de chats existentes
- Sin chat seleccionado ‚Üí Muestra UI de "selecciona o crea"
- Chat se crea SOLO cuando usuario env√≠a primer mensaje

---

## üìÅ Archivos Clave para Referencia

| Archivo | Prop√≥sito |
|---------|-----------|
| `backend/src/agents/router_agent.py` | Decide qu√© agente usar |
| `backend/src/agents/content_generator_agent.py` | Genera contenido - PROMPT PRINCIPAL |
| `backend/src/agents/buyer_persona_agent.py` | Analiza audiencia |
| `backend/src/services/memory_manager.py` | Recopila contexto de todas las fuentes |
| `backend/src/services/rag_service.py` | B√∫squeda sem√°ntica |
| `backend/src/services/llm_service.py` | Comunicaci√≥n con OpenAI/OpenRouter |
| `frontend/app/components/ChatInterface.tsx` | UI del chat |
| `frontend/app/components/MessageList.tsx` | Renderiza mensajes (sin Markdown) |
| `frontend/app/components/ChatPageContent.tsx` | L√≥gica de inicializaci√≥n de chat |

---

*Documento creado como parte de TAREA 7 - Documentaci√≥n del Sistema*
